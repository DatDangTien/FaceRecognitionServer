{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "073ee27d",
   "metadata": {},
   "source": [
    "# Export Pytorch to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805bc7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naiscorp/miniconda3/envs/face_rec/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from facenet.models.mtcnn import MTCNN, RNet, ONet, PNet\n",
    "from facenet.models.inception_resnet_v1 import InceptionResnetV1\n",
    "from face_config import FaceRecognitionConfig\n",
    "import os\n",
    "import cv2\n",
    "import onnxruntime as ort\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6f52e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "output_dir = \"./models\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7735c3",
   "metadata": {},
   "source": [
    "## Test MTCNN Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e1909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 160, 160])\n",
      "cpu\n",
      "(1, 4) (1,) (1, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "mtcnn = MTCNN(device=device)\n",
    "\n",
    "input = cv2.imread(\"data/anh-son-tung-mtp-thumb.jpg\")\n",
    "faces = mtcnn(input)\n",
    "print(faces.shape)\n",
    "print(faces.device)\n",
    "\n",
    "boxes, probs, points = mtcnn.detect(input, landmarks=True)\n",
    "print(boxes.shape, probs.shape, points.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2375a3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 160, 160])\n",
      "cpu\n",
      "(1, 4) (1,) (1, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "mtcnn = MTCNN(device=device)\n",
    "\n",
    "input = cv2.imread(\"data/anh-son-tung-mtp-thumb.jpg\")\n",
    "faces = mtcnn(input)\n",
    "print(faces.shape)\n",
    "print(faces.device)\n",
    "\n",
    "boxes, probs, points = mtcnn.detect(input, landmarks=True)\n",
    "print(boxes.shape, probs.shape, points.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29a80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 123, 123]) torch.Size([1, 2, 123, 123])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pnet = PNet(pretrained=True)\n",
    "pnet.eval().to(device)\n",
    "\n",
    "dummy_input = torch.randn(1,3,256,256, device=device)\n",
    "reg, probs = pnet(dummy_input)\n",
    "\n",
    "print(reg.shape, probs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d98168b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_148539/418914609.py:1: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    pnet,\n",
    "    (dummy_input,),\n",
    "    os.path.join(output_dir, device + \"_pnet.onnx\"),\n",
    "    export_params=True,\n",
    "    opset_version=12,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['bbox_regression', 'face_probability'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size', 2: 'height', 3: 'width'},\n",
    "        'bbox_regression': {0: 'batch_size', 2: 'height', 3: 'width'},\n",
    "        'face_probability': {0: 'batch_size', 2: 'height', 3: 'width'}\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "547f5423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4]) torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "rnet = RNet(pretrained=True)\n",
    "rnet.eval().to(device)\n",
    "\n",
    "dummy_input = torch.randn(1,3,24,24, device=device)\n",
    "reg, probs = rnet(dummy_input)\n",
    "\n",
    "print(reg.shape, probs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d46a70c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_148539/561709744.py:1: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    rnet,\n",
    "    (dummy_input,),\n",
    "    os.path.join(output_dir, device + \"_rnet.onnx\"),\n",
    "    export_params=True,\n",
    "    opset_version=12,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['bbox_regression', 'face_probability'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'bbox_regression': {0: 'batch_size'},\n",
    "        'face_probability': {0: 'batch_size'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc023bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4]) torch.Size([1, 10]) torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "onet = ONet(pretrained=True)\n",
    "onet.eval().to(device)\n",
    "\n",
    "dummy_input = torch.randn(1,3,48,48, device=device)\n",
    "reg, points, probs = onet(dummy_input)\n",
    "\n",
    "print(reg.shape, points.shape, probs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1eccd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_148539/2649185974.py:1: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    onet,\n",
    "    (dummy_input,),\n",
    "    os.path.join(output_dir, device + \"_onet.onnx\"),\n",
    "    export_params=True,\n",
    "    opset_version=12,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['bbox_regression', 'landmarks', 'face_probability'],  \n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'bbox_regression': {0: 'batch_size'},\n",
    "        'landmarks': {0: 'batch_size'},\n",
    "        'face_probability': {0: 'batch_size'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e3985a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_148539/3821756062.py:7: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
      "  torch.onnx.export(\n"
     ]
    }
   ],
   "source": [
    "inception = InceptionResnetV1(pretrained='casia-webface').eval().to(device)\n",
    "\n",
    "inception_input = faces.unsqueeze(0).to(device)\n",
    "output = inception(inception_input)\n",
    "print(output.shape)\n",
    "\n",
    "torch.onnx.export(\n",
    "    inception,\n",
    "    (inception_input,),\n",
    "    os.path.join(output_dir, device + \"_inception.onnx\"),\n",
    "    export_params=True,\n",
    "    opset_version=12,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52675027",
   "metadata": {},
   "source": [
    "# Verify ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d79b11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'MIGraphXExecutionProvider', 'ROCMExecutionProvider', 'OpenVINOExecutionProvider', 'DnnlExecutionProvider', 'TvmExecutionProvider', 'VitisAIExecutionProvider', 'QNNExecutionProvider', 'NnapiExecutionProvider', 'VSINPUExecutionProvider', 'JsExecutionProvider', 'CoreMLExecutionProvider', 'ArmNNExecutionProvider', 'ACLExecutionProvider', 'DmlExecutionProvider', 'RknpuExecutionProvider', 'WebNNExecutionProvider', 'WebGpuExecutionProvider', 'XnnpackExecutionProvider', 'CANNExecutionProvider', 'AzureExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "print(ort.get_available_providers())\n",
    "print(ort.get_all_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9758f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnet_session = ort.InferenceSession(os.path.join(output_dir, device + \"_pnet.onnx\"), providers=['CPUExecutionProvider'])\n",
    "rnet_session = ort.InferenceSession(os.path.join(output_dir, device + \"_rnet.onnx\"), providers=['CPUExecutionProvider'])\n",
    "onet_session = ort.InferenceSession(os.path.join(output_dir, device + \"_onet.onnx\"), providers=['CPUExecutionProvider'])\n",
    "inception_session = ort.InferenceSession(os.path.join(output_dir, device + \"_inception.onnx\"), providers=['CPUExecutionProvider'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3f366e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNet\n",
      "Input 0: name=input, shape=['batch_size', 3, 'height', 'width'], dtype=tensor(float)\n",
      "Output 0: name=bbox_regression, shape=['batch_size', 4, 'height', 'width'], dtype=tensor(float)\n",
      "Output 1: name=face_probability, shape=['batch_size', 2, 'height', 'width'], dtype=tensor(float)\n",
      "RNet\n",
      "Input 0: name=input, shape=['batch_size', 3, 24, 24], dtype=tensor(float)\n",
      "Output 0: name=bbox_regression, shape=['batch_size', 4], dtype=tensor(float)\n",
      "Output 1: name=face_probability, shape=['batch_size', 2], dtype=tensor(float)\n",
      "ONet\n",
      "Input 0: name=input, shape=['batch_size', 3, 48, 48], dtype=tensor(float)\n",
      "Output 0: name=bbox_regression, shape=['batch_size', 4], dtype=tensor(float)\n",
      "Output 1: name=landmarks, shape=['batch_size', 10], dtype=tensor(float)\n",
      "Output 2: name=face_probability, shape=['batch_size', 2], dtype=tensor(float)\n",
      "Inception\n",
      "Input 0: name=input, shape=[1, 3, 160, 160], dtype=tensor(float)\n",
      "Output 0: name=output, shape=[1, 512], dtype=tensor(float)\n"
     ]
    }
   ],
   "source": [
    "# List all input nodes\n",
    "print('PNet')\n",
    "for i, input in enumerate(pnet_session.get_inputs()):\n",
    "    print(f\"Input {i}: name={input.name}, shape={input.shape}, dtype={input.type}\")\n",
    "\n",
    "# List all output nodes\n",
    "for i, output in enumerate(pnet_session.get_outputs()):\n",
    "    print(f\"Output {i}: name={output.name}, shape={output.shape}, dtype={output.type}\")\n",
    "\n",
    "print('RNet')\n",
    "for i, input in enumerate(rnet_session.get_inputs()):\n",
    "    print(f\"Input {i}: name={input.name}, shape={input.shape}, dtype={input.type}\")\n",
    "\n",
    "for i, output in enumerate(rnet_session.get_outputs()):\n",
    "    print(f\"Output {i}: name={output.name}, shape={output.shape}, dtype={output.type}\")\n",
    "\n",
    "print('ONet')\n",
    "for i, input in enumerate(onet_session.get_inputs()):\n",
    "    print(f\"Input {i}: name={input.name}, shape={input.shape}, dtype={input.type}\")\n",
    "\n",
    "for i, output in enumerate(onet_session.get_outputs()):\n",
    "    print(f\"Output {i}: name={output.name}, shape={output.shape}, dtype={output.type}\")\n",
    "\n",
    "print('Inception')\n",
    "for i, input in enumerate(inception_session.get_inputs()):\n",
    "    print(f\"Input {i}: name={input.name}, shape={input.shape}, dtype={input.type}\")\n",
    "\n",
    "for i, output in enumerate(inception_session.get_outputs()):\n",
    "    print(f\"Output {i}: name={output.name}, shape={output.shape}, dtype={output.type}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "495e16da",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"data/anh-son-tung-mtp-thumb.jpg\")\n",
    "input = np.asarray(img).transpose(2, 0, 1)\n",
    "input = np.expand_dims(input, 0).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e358102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.random.randn(1,3,256,256).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14dc7a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 123, 123)\n",
      "(1, 2, 123, 123)\n"
     ]
    }
   ],
   "source": [
    "outputs = pnet_session.run(None, {'input': input})\n",
    "print(outputs[0].shape)\n",
    "print(outputs[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e803288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 4)\n",
      "(12, 2)\n"
     ]
    }
   ],
   "source": [
    "rnet_input = np.random.randn(12,3,24,24).astype(np.float32)\n",
    "rnet_outputs = rnet_session.run(None, {'input': rnet_input})\n",
    "print(rnet_outputs[0].shape)\n",
    "print(rnet_outputs[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8669e897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n",
      "(1, 10)\n",
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "onet_input = np.random.randn(1,3,48,48).astype(np.float32)\n",
    "onet_outputs = onet_session.run(None, {'input': onet_input})\n",
    "print(onet_outputs[0].shape)\n",
    "print(onet_outputs[1].shape)\n",
    "print(onet_outputs[2].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65b69ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512)\n"
     ]
    }
   ],
   "source": [
    "inception_input = np.random.randn(1,3,160,160).astype(np.float32)\n",
    "inception_outputs = inception_session.run(None, {'input': inception_input})\n",
    "print(inception_outputs[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58cfb7e",
   "metadata": {},
   "source": [
    "# Build NCNN engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28848a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
