import cv2
from facenet_pytorch import MTCNN, InceptionResnetV1
import torch
import numpy as np
import os
from face_config import FaceRecognitionConfig

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print("Using device:", device)

DATA_PATH = './data'
os.makedirs(DATA_PATH, exist_ok=True)

def load_existing_data():
    """Load existing embeddings and usernames"""
    embeddings = None
    usernames = None
    
    # Load embeddings
    if device.type == 'cpu':
        embedding_file = os.path.join(DATA_PATH, "faceslistCPU.pth")
    else:
        embedding_file = os.path.join(DATA_PATH, "faceslist.pth")
    
    if os.path.exists(embedding_file):
        embeddings = torch.load(embedding_file)
        print(f"Loaded embeddings: {embeddings.shape}")
    
    # Load usernames
    username_file = os.path.join(DATA_PATH, "usernames.npy")
    if os.path.exists(username_file):
        usernames = np.load(username_file)
        print(f"Loaded usernames: {usernames}")
    
    return embeddings, usernames

def validate_face_quality(face_tensor, frame_roi, mode='registration'):
    """Kiá»ƒm tra cháº¥t lÆ°á»£ng face trÆ°á»›c khi lÆ°u embedding"""
    # Get thresholds from config based on mode
    thresholds = FaceRecognitionConfig.get_quality_thresholds(mode)
    
    quality_score = 0.0
    checks_passed = 0
    total_checks = 4
    
    # Convert tensor to numpy for OpenCV operations
    if isinstance(face_tensor, torch.Tensor):
        # face_tensor shape: [3, 160, 160] -> [160, 160, 3]
        face_np = face_tensor.permute(1, 2, 0).cpu().numpy()
        face_np = ((face_np + 1) * 127.5).astype(np.uint8)  # Denormalize [-1,1] to [0,255]
    else:
        face_np = frame_roi
    
    # 1. Blur Detection (Laplacian variance)
    gray = cv2.cvtColor(face_np, cv2.COLOR_RGB2GRAY) if len(face_np.shape) == 3 else face_np
    blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()
    if blur_score > thresholds['blur_threshold']:
        quality_score += 0.25
        checks_passed += 1
    
    # 2. Face Size Validation
    face_height, face_width = gray.shape[:2]
    if face_height >= thresholds['min_face_size'] and face_width >= thresholds['min_face_size']:
        quality_score += 0.25
        checks_passed += 1
    
    # 3. Lighting Condition (histogram analysis)
    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
    dark_pixels = np.sum(hist[:50])
    bright_pixels = np.sum(hist[200:])
    total_pixels = face_height * face_width
    
    dark_ratio = dark_pixels / total_pixels
    bright_ratio = bright_pixels / total_pixels
    
    if dark_ratio < thresholds['dark_ratio_threshold'] and bright_ratio < thresholds['bright_ratio_threshold']:
        quality_score += 0.25
        checks_passed += 1
    
    # 4. Pose Estimation (basic symmetry check)
    mid_point = face_width // 2
    left_half = gray[:, :mid_point]
    right_half = gray[:, mid_point:]
    right_half_flipped = cv2.flip(right_half, 1)
    
    min_width = min(left_half.shape[1], right_half_flipped.shape[1])
    left_resized = cv2.resize(left_half, (min_width, face_height))
    right_resized = cv2.resize(right_half_flipped, (min_width, face_height))
    
    mse = np.mean((left_resized.astype(float) - right_resized.astype(float)) ** 2)
    if mse < thresholds['pose_threshold']:
        quality_score += 0.25
        checks_passed += 1
    
    # Print quality details for debugging
    print(f"Quality Check - Blur: {blur_score:.1f}, Size: {face_width}x{face_height}, "
          f"Dark: {dark_ratio:.2f}, Bright: {bright_ratio:.2f}, Pose MSE: {mse:.1f}")
    print(f"Checks passed: {checks_passed}/{total_checks}, Quality score: {quality_score:.2f}")
    
    return quality_score >= thresholds['quality_threshold'], quality_score

def save_data(embeddings, usernames):
    """Save embeddings and usernames to files"""
    # Save embeddings
    if device.type == 'cpu':
        torch.save(embeddings, os.path.join(DATA_PATH, "faceslistCPU.pth"))
    else:
        torch.save(embeddings, os.path.join(DATA_PATH, "faceslist.pth"))
    
    # Save usernames
    np.save(os.path.join(DATA_PATH, "usernames.npy"), usernames)
    print(f"âœ… Data saved successfully!")

def show_user_list(usernames):
    """Display list of registered users"""
    if usernames is None or len(usernames) == 0:
        print("ğŸ“‹ Danh sÃ¡ch user trá»‘ng")
        return
    
    print("\nğŸ“‹ DANH SÃCH USER ÄÃƒ ÄÄ‚NG KÃ:")
    print("-" * 40)
    for i, username in enumerate(usernames, 1):
        print(f"{i}. {username}")
    print("-" * 40)
    print(f"Tá»•ng cá»™ng: {len(usernames)} user(s)")

def delete_user(embeddings, usernames):
    """Delete a specific user"""
    if usernames is None or len(usernames) == 0:
        print("âŒ KhÃ´ng cÃ³ user nÃ o Ä‘á»ƒ xÃ³a")
        return embeddings, usernames
    
    show_user_list(usernames)
    
    while True:
        try:
            choice = input(f"\nChá»n user cáº§n xÃ³a (1-{len(usernames)}) hoáº·c 'q' Ä‘á»ƒ há»§y: ").strip()
            if choice.lower() == 'q':
                print("âŒ Há»§y xÃ³a user")
                return embeddings, usernames
            
            user_index = int(choice) - 1
            if 0 <= user_index < len(usernames):
                user_to_delete = usernames[user_index]
                confirm = input(f"Báº¡n cÃ³ cháº¯c muá»‘n xÃ³a user '{user_to_delete}'? (y/n): ").lower().strip()
                
                if confirm in ['y', 'yes', 'cÃ³']:
                    # Remove user from usernames
                    new_usernames = np.delete(usernames, user_index)
                    
                    # Remove corresponding embedding
                    if embeddings is not None:
                        new_embeddings = torch.cat([embeddings[:user_index], embeddings[user_index+1:]])
                    else:
                        new_embeddings = None
                    
                    # Save updated data
                    save_data(new_embeddings, new_usernames)
                    print(f"âœ… ÄÃ£ xÃ³a user '{user_to_delete}' thÃ nh cÃ´ng!")
                    return new_embeddings, new_usernames
                else:
                    print("âŒ Há»§y xÃ³a user")
                    return embeddings, usernames
            else:
                print(f"âŒ Vui lÃ²ng chá»n sá»‘ tá»« 1 Ä‘áº¿n {len(usernames)}")
        except ValueError:
            print("âŒ Vui lÃ²ng nháº­p sá»‘ há»£p lá»‡")

def register_new_user():
    """Register a new user"""
    usr_name = input("Input your name: ")
    if not usr_name.strip():
        print("âŒ TÃªn khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng")
        return
    
    count = FaceRecognitionConfig.REGISTRATION_SAMPLES
    embeddings = []
    
    # Biáº¿n Ä‘áº¿m Ä‘á»ƒ theo dÃµi quality
    total_tensors_processed = 0
    good_quality_tensors = 0
    rejected_tensors = 0
    
    mtcnn = MTCNN(
        margin=FaceRecognitionConfig.MTCNN_MARGIN,
        keep_all=FaceRecognitionConfig.MTCNN_KEEP_ALL,
        select_largest=FaceRecognitionConfig.MTCNN_SELECT_LARGEST,
        post_process=FaceRecognitionConfig.MTCNN_POST_PROCESS,
        device=device
    )
    
    model_embedding = InceptionResnetV1(
        classify=False,
        pretrained="casia-webface"
    ).to(device)
    model_embedding.eval()
    
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FaceRecognitionConfig.CAMERA_WIDTH)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FaceRecognitionConfig.CAMERA_HEIGHT)
    
    # Khá»Ÿi táº¡o tracker
    trackers = []
    tracker_initialized = False
    detection_interval = FaceRecognitionConfig.DETECTION_INTERVAL
    frame_count = 0
    
    leap = 1
    print(f"ğŸ¥ Báº¯t Ä‘áº§u capture face cho user '{usr_name}'...")
    print("Nháº¥n ESC Ä‘á»ƒ thoÃ¡t")
    
    # Hiá»ƒn thá»‹ config hiá»‡n táº¡i
    FaceRecognitionConfig.print_config()
    
    while cap.isOpened() and count > 0:
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_count += 1
        
        # Detect faces má»›i hoáº·c khi chÆ°a cÃ³ tracker
        if not tracker_initialized or frame_count % detection_interval == 0:
            boxes, _, points_list = mtcnn.detect(frame, landmarks=True)
            if boxes is not None:
                # Táº¡o trackers má»›i
                trackers = []
                for box in boxes:
                    tracker = cv2.legacy.TrackerCSRT_create()
                    bbox = (int(box[0]), int(box[1]), int(box[2]-box[0]), int(box[3]-box[1]))
                    tracker.init(frame, bbox)
                    trackers.append(tracker)
                tracker_initialized = True
        
        # Update trackers vÃ  váº½ bounding boxes
        if tracker_initialized and trackers:
            for i, tracker in enumerate(trackers):
                success, bbox = tracker.update(frame)
                if success:
                    # Váº½ bbox tá»« tracker
                    x, y, w, h = [int(v) for v in bbox]
                    frame = cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 6)
                    
                    # Láº¥y face tá»« bbox Ä‘á»ƒ extract embedding
                    if leap % FaceRecognitionConfig.REGISTRATION_SKIP_FRAMES == 0:
                        face_roi = frame[y:y+h, x:x+w]
                        if face_roi.size > 0:
                            face_rgb = cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)
                            
                            face_tensor = mtcnn(face_rgb)
                            if face_tensor is not None:
                                total_tensors_processed += 1
                                
                                # Validate face quality before saving
                                is_good_quality, quality_score = validate_face_quality(face_tensor, face_rgb, mode='registration')
                                
                                if is_good_quality:
                                    good_quality_tensors += 1
                                    with torch.no_grad():
                                        embedding = model_embedding(face_tensor.unsqueeze(0).to(device))
                                        embeddings.append(embedding)
                                    count -= 1
                                    print(f"âœ… Captured good quality embedding {FaceRecognitionConfig.REGISTRATION_SAMPLES-count}/{FaceRecognitionConfig.REGISTRATION_SAMPLES} (Quality: {quality_score:.2f})")
                                else:
                                    rejected_tensors += 1
                                    print(f"âŒ Poor quality face rejected (Quality: {quality_score:.2f})")
        
        # Hiá»ƒn thá»‹ progress vÃ  quality feedback
        cv2.putText(frame, f"Progress: {FaceRecognitionConfig.REGISTRATION_SAMPLES-count}/{FaceRecognitionConfig.REGISTRATION_SAMPLES}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(frame, f"User: {usr_name}", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(frame, f"Good: {good_quality_tensors} | Rejected: {rejected_tensors}", (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        cv2.putText(frame, f"Total processed: {total_tensors_processed}", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        cv2.putText(frame, "Keep face steady & well-lit", (10, 190), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        
        leap += 1
        
        cv2.imshow("Face Capturing", frame)
        if cv2.waitKey(1) & 0xFF == 27:
            break
    
    cap.release()
    cv2.destroyAllWindows()
    
    # Xá»­ lÃ½ káº¿t quáº£
    if len(embeddings) > 0:
        embedding = torch.cat(embeddings).mean(0, keepdim=True)
        names = np.array([usr_name])
        
        # Load existing data
        existing_embeddings, existing_usernames = load_existing_data()
        
        # Merge with existing data
        if existing_embeddings is not None:
            new_embeddings = torch.cat([existing_embeddings, embedding])
            new_usernames = np.concatenate([existing_usernames, names])
        else:
            new_embeddings = embedding
            new_usernames = names
        
        # Save data
        save_data(new_embeddings, new_usernames)
        print(f'âœ… ÄÄƒng kÃ½ user "{usr_name}" thÃ nh cÃ´ng!')
        
        # Hiá»ƒn thá»‹ thá»‘ng kÃª cuá»‘i cÃ¹ng
        print("\nğŸ“Š THá»NG KÃŠ CHáº¤T LÆ¯á»¢NG:")
        print(f"   â€¢ Tá»•ng sá»‘ tensor Ä‘Ã£ xá»­ lÃ½: {total_tensors_processed}")
        print(f"   â€¢ Sá»‘ tensor Ä‘á»§ Ä‘iá»u kiá»‡n: {good_quality_tensors}")
        print(f"   â€¢ Sá»‘ tensor bá»‹ tá»« chá»‘i: {rejected_tensors}")
        if total_tensors_processed > 0:
            success_rate = (good_quality_tensors / total_tensors_processed) * 100
            print(f"   â€¢ Tá»· lá»‡ thÃ nh cÃ´ng: {success_rate:.1f}%")
        
    else:
        print("âŒ KhÃ´ng cÃ³ embedding nÃ o Ä‘Æ°á»£c capture. ÄÄƒng kÃ½ tháº¥t báº¡i.")
        print("\nğŸ“Š THá»NG KÃŠ CHáº¤T LÆ¯á»¢NG:")
        print(f"   â€¢ Tá»•ng sá»‘ tensor Ä‘Ã£ xá»­ lÃ½: {total_tensors_processed}")
        print(f"   â€¢ Sá»‘ tensor Ä‘á»§ Ä‘iá»u kiá»‡n: {good_quality_tensors}")
        print(f"   â€¢ Sá»‘ tensor bá»‹ tá»« chá»‘i: {rejected_tensors}")
        if total_tensors_processed > 0:
            success_rate = (good_quality_tensors / total_tensors_processed) * 100
            print(f"   â€¢ Tá»· lá»‡ thÃ nh cÃ´ng: {success_rate:.1f}%")

def main_menu():
    """Main menu system"""
    while True:
        print("\n" + "="*50)
        print("ğŸ­ FACE RECOGNITION SYSTEM")
        print("="*50)
        print("1. ğŸ“ ÄÄƒng kÃ½ user má»›i")
        print("2. ğŸ“‹ Xem danh sÃ¡ch user")
        print("3. ğŸ—‘ï¸  XÃ³a user")
        print("4. âŒ ThoÃ¡t")
        print("="*50)
        
        choice = input("Chá»n chá»©c nÄƒng (1-4): ").strip()
        
        if choice == '1':
            register_new_user()
        elif choice == '2':
            _, usernames = load_existing_data()
            show_user_list(usernames)
        elif choice == '3':
            embeddings, usernames = load_existing_data()
            delete_user(embeddings, usernames)
        elif choice == '4':
            print("ğŸ‘‹ Táº¡m biá»‡t!")
            break
        else:
            print("âŒ Vui lÃ²ng chá»n tá»« 1-4")

if __name__ == "__main__":
    main_menu()